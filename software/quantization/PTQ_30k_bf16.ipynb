{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyN5JU0dwcyQBU/a6iXH2rDc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4uOy1pdtuO_","executionInfo":{"status":"ok","timestamp":1735195669137,"user_tz":-330,"elapsed":27688,"user":{"displayName":"Chaitanya","userId":"11737175569404139358"}},"outputId":"cad657d4-1cf5-4e32-eecb-f61eddf649fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import tensorflow as tf\n","from tensorflow.keras.models import load_model\n","import numpy as np"]},{"cell_type":"code","source":["# Step 1: Load the trained model\n","model_path = '/content/drive/MyDrive/30000/best_30000_17db_model.h5'\n","model = load_model(model_path)\n","\n","# Step 2: Load training and validation data\n","X_train = np.load('/content/drive/MyDrive/30000/merged_signals_30000.npy')\n","y_train = np.load('/content/drive/MyDrive/30000/merged_labels_30000.npy')\n","\n","# Split data into training and validation sets\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n","\n","print(f\"Training Data Shape: {X_train.shape}\")\n","print(f\"Validation Data Shape: {X_val.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nxZ-q4uWuEJ6","executionInfo":{"status":"ok","timestamp":1735196005685,"user_tz":-330,"elapsed":312322,"user":{"displayName":"Chaitanya","userId":"11737175569404139358"}},"outputId":"a0955556-4f9c-4353-941d-bf5691914f49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Data Shape: (48000, 36, 1000, 2)\n","Validation Data Shape: (12000, 36, 1000, 2)\n"]}]},{"cell_type":"code","source":["# Step 3: Convert the model to TensorFlow Lite format with BF16 quantization\n","def convert_to_tflite_bf16(model, X_train):\n","    # Define the representative dataset generator\n","    def representative_dataset_generator():\n","        for i in range(len(X_train)):\n","            yield [np.expand_dims(X_train[i], axis=0)]\n","\n","    # Convert the model to TensorFlow Lite format with BF16 quantization\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    converter.representative_dataset = representative_dataset_generator\n","    converter.target_spec.supported_types = [tf.float16]\n","\n","    tflite_model = converter.convert()\n","    return tflite_model\n","\n","print(\"Converting the model to TensorFlow Lite format with BF16 quantization...\")\n","bf16_tflite_model = convert_to_tflite_bf16(model, X_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LiuMcqc8uQ1A","executionInfo":{"status":"ok","timestamp":1735196007556,"user_tz":-330,"elapsed":1879,"user":{"displayName":"Chaitanya","userId":"11737175569404139358"}},"outputId":"8288f2bf-e07e-4ca7-e2e3-69cc6d926b47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Converting the model to TensorFlow Lite format with BF16 quantization...\n"]}]},{"cell_type":"code","source":["# Step 4: Save the converted TFLite model\n","tflite_model_path = '/content/drive/MyDrive/30000/best_30000_17db_model_bf16.tflite'\n","with open(tflite_model_path, 'wb') as f:\n","    f.write(bf16_tflite_model)\n","\n","print(f\"BF16 quantized model saved to {tflite_model_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhKy7-axubad","executionInfo":{"status":"ok","timestamp":1735196007556,"user_tz":-330,"elapsed":10,"user":{"displayName":"Chaitanya","userId":"11737175569404139358"}},"outputId":"aaa0ec53-d9d6-4a3c-ad6d-1b0195c476eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BF16 quantized model saved to /content/drive/MyDrive/30000/best_30000_17db_model_bf16.tflite\n"]}]},{"cell_type":"code","source":["# Step 5: Evaluate the BF16 quantized TFLite model\n","def evaluate_tflite_model(tflite_model_path, X_val, y_val):\n","    # Load the TFLite model and allocate tensors\n","    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n","    interpreter.allocate_tensors()\n","\n","    # Get input and output details\n","    input_details = interpreter.get_input_details()\n","    output_details = interpreter.get_output_details()\n","\n","    correct_predictions = 0\n","\n","    # Perform inference on the validation set\n","    for i in range(len(X_val)):\n","        input_data = np.expand_dims(X_val[i], axis=0).astype(input_details[0]['dtype'])\n","        interpreter.set_tensor(input_details[0]['index'], input_data)\n","        interpreter.invoke()\n","        output_data = interpreter.get_tensor(output_details[0]['index'])\n","\n","        # Apply threshold to classify\n","        predicted_label = (output_data >= 0.5).astype(int)\n","        true_label = y_val[i]\n","\n","        if len(true_label.shape) > 1:\n","            true_label = np.argmax(true_label)\n","\n","        if predicted_label == true_label:\n","            correct_predictions += 1\n","\n","    accuracy = correct_predictions / len(X_val)\n","    return accuracy\n","\n","print(\"Evaluating the BF16 quantized TFLite model...\")\n","bf16_accuracy = evaluate_tflite_model(tflite_model_path, X_val, y_val)\n","print(f\"Accuracy of the BF16 quantized model: {bf16_accuracy:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wQ2SaTvcugzI","executionInfo":{"status":"ok","timestamp":1735197564777,"user_tz":-330,"elapsed":222362,"user":{"displayName":"Chaitanya","userId":"11737175569404139358"}},"outputId":"e9ed910c-8c40-4173-ba9d-d8a18e8db687"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating the BF16 quantized TFLite model...\n","Accuracy of the BF16 quantized model: 0.7522\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"0FpAka-jyGUs"},"execution_count":null,"outputs":[]}]}